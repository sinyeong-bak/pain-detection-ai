import os
import librosa
import numpy as np

# âœ… CREMA-D ë°ì´í„° ê²½ë¡œ
AUDIO_PATH = "Processed_Audio/train"
PROCESSED_AUDIO_DIR = "processed_audio"
os.makedirs(PROCESSED_AUDIO_DIR, exist_ok=True)

# âœ… ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ í•¨ìˆ˜ (MFCC ë³€í™˜)
def preprocess_audio(file_path, max_length=100):
    audio, sr = librosa.load(file_path, sr=16000)  # ìƒ˜í”Œë§ ì†ë„ 16kHz
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)

    # í´¹ ê³ ì •ëœ ê¸¸ì´ë¡œ íŒ¨ë”©
    if mfcc.shape[1] < max_length:
        pad_width = max_length - mfcc.shape[1]
        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')
    else:
        mfcc = mfcc[:, :max_length]  # ê¸¸ì´ê°€ ê¸¸ë©´ ìë¦„

    return mfcc

# âœ… ê°ì • í´ë˜ìŠ¤ë³„ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì²˜ë¦¬
for emotion in os.listdir(AUDIO_PATH):
    emotion_path = os.path.join(AUDIO_PATH, emotion)
    save_path = os.path.join(PROCESSED_AUDIO_DIR, emotion)
    os.makedirs(save_path, exist_ok=True)

    for file in os.listdir(emotion_path):
        file_path = os.path.join(emotion_path, file)
        processed_audio = preprocess_audio(file_path)

        # âœ… ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì €ì¥ (ë„˜íŒŒì´ ë°°ì—´ í˜•íƒœ)
        np.save(os.path.join(save_path, file.replace(".wav", ".npy")), processed_audio)

print("âœ… CREMA-D ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
